{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Imbalance Problems - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "\n",
    "Now that you've gone over some techniques for tuning classification models on imbalanced datasets, its time to practice those techniques. In this lab, you'll investigate credit card fraud and attempt to tune a model to flag suspicious activity.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "* Use modified sampling techniques to address class imbalance problems\n",
    "* Understand the complications of class imbalance problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Credit Card Fraud\n",
    "Load the **creditcard.csv.gz** file and preview the data. To load a compressed csv use the optional parameter compression='gzip' within pandas read_csv method as in: `pd.read_csv(filename, compression='gzip')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"creditcard.csv.gz\", compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview the class imbalance\n",
    "\n",
    "You should see that the dataset has 31 columns. The first is a time field followed by V1-V28, created by way of manual feature engineering done on the backend that we have little information about. Finally, there's the amount of the purchase and a binary Class flag. This last column, Class, is the indication of whether or not the purchase was fraudulent, and it is the feature you should be attempting to predict.\n",
    "\n",
    "Take a look at how imbalanced this dataset is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Class\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Problem\n",
    "\n",
    "Define X and y and perform a standard train test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop(\"Class\", axis=1), df[\"Class\"]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "test_size=0.33, \n",
    "random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an initial model\n",
    "\n",
    "As a baseline, fit a cookie cutter out of the box logistic regression model. Then plot the ROC curve and print out the AUC. We'll use this as a comparison for how our future models perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.884988995027987"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(fit_intercept = False, C=1e12)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_hat_test = logreg.predict(X_test)\n",
    "y_hat_train = logreg.predict(X_train)\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "y_score = logreg.fit(X_train, y_train).decision_function(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_score)\n",
    "auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f97b4d79f98>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAEClJREFUeJzt3X+IpVd9x/H3J0lTaZuY2l0hJrvuSjfgmBaVIVEKNWIsm4BZBGs3RVpLcKttLFQppLVEiVBaxUqFRd3a4A+IMQo1g6yk1EYs4m4zwTSalZRt1GRMaEZN4x+iMfjtH3c2vZmdmfvMzP0x99z3Cxbu89wz937P3tlPTs49z3NSVUiS2nLOpAuQJA2f4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lq0HmTeuNdu3bVvn37JvX2kjSV7r333u9X1e5B7SYW7vv27WNxcXFSby9JUynJd7u0c1pGkhpkuEtSgwx3SWqQ4S5JDTLcJalBA8M9ya1JHk/yzXWeT5IPJTmd5P4kLx9+mZKkzegycv84cHCD568BDqz8OQJ8ePtlSZK2Y+A696r6SpJ9GzQ5BHyyevv1nUhyUZKLq+qxIdUoSVPvtpMPc+d93wNg7gUX8u7XvWSk7zeMOfdLgEf6jpdWzp0lyZEki0kWl5eXh/DWkjQd7rzve5x67Edje79hXKGaNc6tuet2VR0DjgHMz8+7M7ekHa9/xL0dpx77EXMXX8hn/viVQ6hqsGGE+xKwp+/4UuDRIbyuJI3coPA++e0fAnDl/udt633mLr6QQy9dc1JjJIYR7gvAjUluB64EnnS+XdJ2DWvEPMig8L5y//M49NJL+P0r9468lmEaGO5JPg1cBexKsgS8G/gFgKr6CHAcuBY4DfwY+KNRFStpdpyZo567+MKRvs+0hvcgXVbLXD/g+QL+dGgVSWrGdkbf456jbo1XqEoame2sEBn3HHVrJnY/d0lt6h+tO/qeHEfukoaqf7Tu6HtyHLlLWtNW58sdre8Mhrs0IeNa6rdVW13f7Wh9ZzDcpQkZ11K/rWp1ieCsMNylCXL6QqPiF6rSBNx28uFnpj2kUXDkLg3BZufPzwS7c9MaFcNd6mDYN5dyPlujZrhLA9x28mH+6p+/AbR3cym1y3CXBjgzYv+b1/+G4a2pYbhLK9abejn12I+4cv/zDHZNFcNdM60/0NebN/eiHE0jw10zYb1ReX+gO2+ulhjumgnrXQ1qoKtVhruatHqk7s2sNGsMd02NzVwotHr+3HlzzRrDXVOhy1rzfk63aNYZ7poKrjWXNsdw18gM837lrjWXNsdw11CsFeRb3exhLc6ZS5tjuGso1lpq6Ly3NDmGu4bGpYbSzmG4a6Auc+c7ebs4aRYZ7jOuS3B3mTt3TlzaWQz3GdZ17bhz59L0MdxnmGvHpXYZ7jNkrfutuHZcapPh3oCuFwt5vxVpdnQK9yQHgX8AzgU+VlV/u+r5vcAngItW2txUVceHXOvM63JP8o04dy7NjoHhnuRc4CjwWmAJuCfJQlWd6mv218AdVfXhJHPAcWDfCOqdad6TXFJXXUbuVwCnq+ohgCS3A4eA/nAv4EziPBd4dJhFzpqN9vL0QiFJXXQJ90uAR/qOl4ArV7V5D/AvSd4O/DJw9VCqm0EbLU90jlxSV13CPWucq1XH1wMfr6oPJHkl8Kkkl1fVz5/1QskR4AjA3r1OIazWH+wuT5S0Hed0aLME7Ok7vpSzp11uAO4AqKqvAc8Bdq1+oao6VlXzVTW/e/furVXcMNedSxqWLuF+D3Agyf4k5wOHgYVVbR4GXgOQ5MX0wn15mIW27LaTD/N7H/2a684lDc3AaZmqejrJjcBd9JY53lpVDyS5BVisqgXgncA/JvlzelM2b66q1VM36tP/pWn/Ukbn1CUNQyaVwfPz87W4uDiR9x63LhtZuJRRUhdJ7q2q+UHtvEJ1DNzIQtK4Ge5j4vp0SeNkuG+TG1lI2om6rJbRBs5MuWzEi48kjZsj9yFwykXSTmO4dzTofi+StJPMdLh3vQ86rH9bXadcJO1EMxHu270P+pk2Ll2UNC1mIty9D7qkWdNUuHsfdEnqaWop5HrLEp0XlzRrmhi5nxmxO0KXpJ4mRu79we4IXZIaGbmDFxJJUr8mRu6SpGeb+nC/7eTDz6xXlyT1TH24n1n66Fy7JP2/qQ93wH1HJWmVJsJdkvRshrskNchwl6QGTXW4u1JGktY21eHuShlJWtvUhvuZUbsrZSTpbFMb7o7aJWl9Uxvu4Pp2SVrPVIe7JGlthrskNchwl6QGGe6S1CDDXZIa1CnckxxM8mCS00luWqfNG5OcSvJAktuGW+azeWWqJG1s4DZ7Sc4FjgKvBZaAe5IsVNWpvjYHgL8Efquqnkjy/FEVDK5xl6RBuozcrwBOV9VDVfUUcDtwaFWbtwBHq+oJgKp6fLhlns017pK0vi7hfgnwSN/x0sq5fpcBlyX5apITSQ6u9UJJjiRZTLK4vLy8tYolSQN1Cfesca5WHZ8HHACuAq4HPpbkorN+qOpYVc1X1fzu3bs3W6skqaMu4b4E7Ok7vhR4dI02d1bVz6rq28CD9MJekjQBXcL9HuBAkv1JzgcOAwur2nweeDVAkl30pmkeGmahkqTuBoZ7VT0N3AjcBXwLuKOqHkhyS5LrVprdBfwgySngbuAvquoHoypakrSxgUshAarqOHB81bmb+x4X8I6VPyPVfx93SdLapu4KVde4S9JgUxfu4Bp3SRpkKsNdkrQxw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJalCncE9yMMmDSU4nuWmDdm9IUknmh1eiJGmzBoZ7knOBo8A1wBxwfZK5NdpdAPwZcHLYRUqSNqfLyP0K4HRVPVRVTwG3A4fWaPde4H3AT4ZYnyRpC7qE+yXAI33HSyvnnpHkZcCeqvrCEGuTJG1Rl3DPGufqmSeTc4APAu8c+ELJkSSLSRaXl5e7VylJ2pQu4b4E7Ok7vhR4tO/4AuBy4MtJvgO8AlhY60vVqjpWVfNVNb979+6tVy1J2lCXcL8HOJBkf5LzgcPAwpknq+rJqtpVVfuqah9wAriuqhZHUrEkaaCB4V5VTwM3AncB3wLuqKoHktyS5LpRFyhJ2rzzujSqquPA8VXnbl6n7VXbL0uStB1eoSpJDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoM6hXuSg0keTHI6yU1rPP+OJKeS3J/kS0leOPxSJUldDQz3JOcCR4FrgDng+iRzq5p9HZivqt8EPge8b9iFSpK66zJyvwI4XVUPVdVTwO3Aof4GVXV3Vf145fAEcOlwy5QkbUaXcL8EeKTveGnl3HpuAL641hNJjiRZTLK4vLzcvUpJ0qZ0Cfesca7WbJi8CZgH3r/W81V1rKrmq2p+9+7d3auUJG3KeR3aLAF7+o4vBR5d3SjJ1cC7gFdV1U+HU54kaSu6jNzvAQ4k2Z/kfOAwsNDfIMnLgI8C11XV48MvU5K0GQPDvaqeBm4E7gK+BdxRVQ8kuSXJdSvN3g/8CvDZJPclWVjn5SRJY9BlWoaqOg4cX3Xu5r7HVw+5LknSNniFqiQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWpQp3BPcjDJg0lOJ7lpjed/MclnVp4/mWTfsAuVJHU3MNyTnAscBa4B5oDrk8ytanYD8ERV/TrwQeDvhl2oJKm7LiP3K4DTVfVQVT0F3A4cWtXmEPCJlcefA16TJMMrU5K0GV3C/RLgkb7jpZVza7apqqeBJ4FfG0aBkqTNO69Dm7VG4LWFNiQ5AhwB2Lt3b4e3PtvcCy7c0s9J0izpEu5LwJ6+40uBR9dps5TkPOC5wA9Xv1BVHQOOAczPz58V/l28+3Uv2cqPSdJM6TItcw9wIMn+JOcDh4GFVW0WgD9cefwG4N+qakvhLUnavoEj96p6OsmNwF3AucCtVfVAkluAxapaAP4J+FSS0/RG7IdHWbQkaWNdpmWoquPA8VXnbu57/BPgd4dbmiRpq7xCVZIaZLhLUoMMd0lqkOEuSQ0y3CWpQZnUcvQky8B3t/jju4DvD7GcaWCfZ4N9ng3b6fMLq2r3oEYTC/ftSLJYVfOTrmOc7PNssM+zYRx9dlpGkhpkuEtSg6Y13I9NuoAJsM+zwT7PhpH3eSrn3CVJG5vWkbskaQM7OtxncWPuDn1+R5JTSe5P8qUkL5xEncM0qM997d6QpJJM/cqKLn1O8saVz/qBJLeNu8Zh6/C7vTfJ3Um+vvL7fe0k6hyWJLcmeTzJN9d5Pkk+tPL3cX+Slw+1gKrakX/o3V74v4EXAecD/wnMrWrzJ8BHVh4fBj4z6brH0OdXA7+08vhts9DnlXYXAF8BTgDzk657DJ/zAeDrwK+uHD9/0nWPoc/HgLetPJ4DvjPpurfZ598GXg58c53nrwW+SG8nu1cAJ4f5/jt55D6LG3MP7HNV3V1VP145PEFvZ6xp1uVzBngv8D7gJ+MsbkS69PktwNGqegKgqh4fc43D1qXPBZzZR/O5nL3j21Spqq+wxo50fQ4Bn6yeE8BFSS4e1vvv5HCfxY25u/S53w30/ss/zQb2OcnLgD1V9YVxFjZCXT7ny4DLknw1yYkkB8dW3Wh06fN7gDclWaK3f8Tbx1PaxGz23/umdNqsY0KGtjH3FOncnyRvAuaBV420otHbsM9JzgE+CLx5XAWNQZfP+Tx6UzNX0fu/s39PcnlV/e+IaxuVLn2+Hvh4VX0gySvp7e52eVX9fPTlTcRI82snj9w3szE3G23MPUW69JkkVwPvAq6rqp+OqbZRGdTnC4DLgS8n+Q69ucmFKf9Stevv9p1V9bOq+jbwIL2wn1Zd+nwDcAdAVX0NeA69e7C0qtO/963ayeE+ixtzD+zzyhTFR+kF+7TPw8KAPlfVk1W1q6r2VdU+et8zXFdVi5Mpdyi6/G5/nt6X5yTZRW+a5qGxVjlcXfr8MPAagCQvphfuy2OtcrwWgD9YWTXzCuDJqnpsaK8+6W+UB3zbfC3wX/S+ZX/Xyrlb6P3jht6H/1ngNPAfwIsmXfMY+vyvwP8A9638WZh0zaPu86q2X2bKV8t0/JwD/D1wCvgGcHjSNY+hz3PAV+mtpLkP+J1J17zN/n4aeAz4Gb1R+g3AW4G39n3GR1f+Pr4x7N9rr1CVpAbt5GkZSdIWGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXo/wBGcbnOliFSTAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning \n",
    "Try some of the various techniques proposed to tune your model. Compare your models using AUC, ROC or another metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9733483279980878"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "weight = 'balanced'\n",
    "logreg = LogisticRegression(fit_intercept = False, C = 1e12, \n",
    "class_weight = weight, solver='lbfgs')\n",
    "logreg.fit(X_train, y_train)\n",
    "y_hat_test = logreg.predict(X_test)\n",
    "y_hat_train = logreg.predict(X_train)\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "y_score = logreg.fit(X_train, y_train).decision_function(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_score)\n",
    "auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.884988995027987"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "X_train_resampled, y_train_resampled = smote.fit_sample(X_train, y_train)\n",
    "logreg = LogisticRegression(fit_intercept = False, C = 1e12)\n",
    "logreg.fit(X_train_resampled, y_train_resampled)\n",
    "y_hat_test = logreg.predict(X_test)\n",
    "y_hat_train = logreg.predict(X_train)\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "y_score = logreg.fit(X_train, y_train).decision_function(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_score)\n",
    "auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE\n",
    "If you haven't already, try using the SMOTE class from the imblearn package in order to improve the model's performance on the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "Describe what is misleading about the AUC score and ROC curves produced by this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    284315\n",
      "1       492\n",
      "Name: Class, dtype: int64\n",
      "1    284315\n",
      "0    284315\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.005, class_weight=None, dual=False,\n",
      "          fit_intercept=False, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,\n",
      "          solver='warn', tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for 0.005: 0.9895051568638292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=False,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for 0.1: 0.9895072288429295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.2, class_weight=None, dual=False, fit_intercept=False,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for 0.2: 0.9895072779307035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "print(y.value_counts()) #Previous original class distribution\n",
    "X_resampled, y_resampled = SMOTE().fit_sample(X, y) \n",
    "print(pd.Series(y_resampled).value_counts()) #Preview synthetic sample class distribution\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, random_state=0)\n",
    "\n",
    "# Now let's compare a few different regularization performances on the dataset:\n",
    "C_param_range = [0.005, 0.1, 0.2, 0.3, 0.5, 0.6, 0.7, 0.8]\n",
    "names = [0.005, 0.1, 0.2, 0.3, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "colors = sns.color_palette(\"Set2\", n_colors=len(names))\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "for n, c in enumerate(C_param_range):\n",
    "    #Fit a model\n",
    "    logreg = LogisticRegression(fit_intercept = False, C = c) #Starter code\n",
    "    model_log = logreg.fit(X_train, y_train)\n",
    "    print(model_log) #Preview model params\n",
    "\n",
    "    #Predict\n",
    "    y_hat_test = logreg.predict(X_test)\n",
    "\n",
    "    y_score = logreg.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_score)\n",
    "    \n",
    "    print('AUC for {}: {}'.format(names[n], auc(fpr, tpr)))\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color=colors[n],\n",
    "             lw=lw, label='ROC curve Normalization Weight: {}'.format(names[n]))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "\n",
    "plt.yticks([i/20.0 for i in range(21)])\n",
    "plt.xticks([i/20.0 for i in range(21)])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rebalancing was done on the test set as well as the training set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, you got some hands-on practice tuning logistic regression models using various techniques and parameters. In the upcoming labs and lessons, you will continue to dig into the underlying mathematics of logistic regression, taking on a statistical point of view and providing you with a deeper understanding of how the algorithm works. This should give you further insight as to how to tune and apply these models going forward."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
